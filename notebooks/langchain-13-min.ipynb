{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C7RnyUOCJWmk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nLarge language models are complex machine learning models built from large datasets of natural language data and used to generate text, recognize speech, and perform other language-related tasks.'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run basic query with OpenAI wrapper\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "llm(\"explain large language models in one sentence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JtHgQ5XpJmgi"
      },
      "outputs": [],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure, here is an example Python script that trains a simple neural network on simulated data using the Keras library:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "\n",
            "# Generate simulated data\n",
            "X = np.random.rand(1000, 10)\n",
            "y = np.sum(X, axis=1)\n",
            "\n",
            "# Define the neural network architecture\n",
            "model = Sequential()\n",
            "model.add(Dense(32, input_dim=10, activation='relu'))\n",
            "model.add(Dense(1, activation='linear'))\n",
            "\n",
            "# Compile the model\n",
            "model.compile(loss='mean_squared_error', optimizer='adam')\n",
            "\n",
            "# Train the model on the simulated data\n",
            "model.fit(X, y, epochs=50, batch_size=32)\n",
            "\n",
            "# Evaluate the model on new data\n",
            "X_test = np.random.rand(100, 10)\n",
            "y_test = np.sum(X_test, axis=1)\n",
            "mse = model.evaluate(X_test, y_test)\n",
            "print(\"Mean squared error:\", mse)\n",
            "```\n",
            "\n",
            "This script generates a simulated dataset with 1000 samples, where each sample has 10 features. The target variable is the sum of the features for each sample. The neural network has one hidden layer with 32 units and a linear output layer. The model is trained for 50 epochs using the mean squared error loss and the Adam optimizer. Finally, the model is evaluated on a new dataset with 100 samples, and the mean squared error is printed.\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
        "]\n",
        "response=chat(messages)\n",
        "\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2grf7I8AJ_hK"
      },
      "outputs": [],
      "source": [
        "# Import prompt and define PromptTemplate\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vcz7Q9Y-KFvI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nAutoencoders are neural networks that learn to compress data using an encoding layer and then decode the data back to its original form using a decoding layer. They are typically used for dimensionality reduction, denoising, and feature learning.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run LLM with PromptTemplate\n",
        "\n",
        "llm(prompt.format(concept=\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dm78i-rUKXIB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "An autoencoder is a type of artificial neural network used to learn efficient data coding in an unsupervised manner. It consists of an encoder and a decoder which maps an input to a compressed representation and then reconstructs the input from this representation. Autoencoders are used for dimensionality reduction, feature learning, and generative modeling.\n"
          ]
        }
      ],
      "source": [
        "# Import LLMChain and define chain with language model and prompt as arguments.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B6MF4-nMKul3"
      },
      "outputs": [],
      "source": [
        "# Define a second prompt \n",
        "\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SkJKFyk1K-MO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "An autoencoder is a type of artificial neural network that is used to learn a compressed representation of input data. It works by learning a series of weights that map an input vector to a hidden representation, and then from the hidden representation back to the original input vector, thus reconstructing the input vector from the hidden representation.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "An autoencoder is a type of machine learning, which is a way for computers to learn by themselves. It is used to learn how to compress data, which means to take a lot of information and make it smaller. This is useful because it can help make computers work faster, as well as help make data easier to store. \n",
            "\n",
            "To do this, an autoencoder uses something called an artificial neural network. This is a type of program that can “think” like a human brain. It can take in a lot of information and figure out what is important and what is not. \n",
            "\n",
            "The autoencoder takes in a bunch of information, called an input vector. It then looks for patterns in the information. It learns a set of weights, which are like rules that tell the autoencoder which parts of the information are important. With these weights, the autoencoder can create a hidden representation of the data. This hidden representation is like a code, which is much smaller than the original data. \n",
            "\n",
            "The autoencoder then takes the hidden representation and turns it back into the original input vector. This is called reconstructing the input vector. This way, the autoenc\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "An autoencoder is a type of machine learning, which is a way for computers to learn by themselves. It is used to learn how to compress data, which means to take a lot of information and make it smaller. This is useful because it can help make computers work faster, as well as help make data easier to store. \n",
            "\n",
            "To do this, an autoencoder uses something called an artificial neural network. This is a type of program that can “think” like a human brain. It can take in a lot of information and figure out what is important and what is not. \n",
            "\n",
            "The autoencoder takes in a bunch of information, called an input vector. It then looks for patterns in the information. It learns a set of weights, which are like rules that tell the autoencoder which parts of the information are important. With these weights, the autoencoder can create a hidden representation of the data. This hidden representation is like a code, which is much smaller than the original data. \n",
            "\n",
            "The autoencoder then takes the hidden representation and turns it back into the original input vector. This is called reconstructing the input vector. This way, the autoenc\n"
          ]
        }
      ],
      "source": [
        "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "explanation = overall_chain.run(\"autoencoder\")\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='An autoencoder is a type of machine learning, which is a way for computers to learn by themselves.', metadata={}),\n",
              " Document(page_content='It is used to learn how to compress data, which means to take a lot of information and make it', metadata={}),\n",
              " Document(page_content='smaller. This is useful because it can help make computers work faster, as well as help make data', metadata={}),\n",
              " Document(page_content='easier to store.', metadata={}),\n",
              " Document(page_content='To do this, an autoencoder uses something called an artificial neural network. This is a type of', metadata={}),\n",
              " Document(page_content='program that can “think” like a human brain. It can take in a lot of information and figure out what', metadata={}),\n",
              " Document(page_content='is important and what is not.', metadata={}),\n",
              " Document(page_content='The autoencoder takes in a bunch of information, called an input vector. It then looks for patterns', metadata={}),\n",
              " Document(page_content='in the information. It learns a set of weights, which are like rules that tell the autoencoder which', metadata={}),\n",
              " Document(page_content='parts of the information are important. With these weights, the autoencoder can create a hidden', metadata={}),\n",
              " Document(page_content='representation of the data. This hidden representation is like a code, which is much smaller than', metadata={}),\n",
              " Document(page_content='the original data.', metadata={}),\n",
              " Document(page_content='The autoencoder then takes the hidden representation and turns it back into the original input', metadata={}),\n",
              " Document(page_content='vector. This is called reconstructing the input vector. This way, the autoenc', metadata={})]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])\n",
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'An autoencoder is a type of machine learning, which is a way for computers to learn by themselves.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "\n",
        "texts[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [],
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.032400242618663484, 0.02961954813553015, 0.012451332853294165, 0.013707795025690132, 0.036355007029591484, 0.01485096925874316, -0.025499999235399546, -0.00615357414394351, 0.020062196773389693, 0.0035402362301041913, -0.042678512151226845, -0.014037358416159945, 0.015067245641192595, 0.03312116451437665, 0.0249850560885445, -0.01296627600014921, 0.04239014488305768, -0.011555330697432215, 0.021071485937272018, 0.0064728389694994415, 0.027106623790738214, 0.005278170514893168, 0.06335864144590064, -0.016910742777485895, 0.03748788269773063, 0.03396566918905637, 0.007399737285764314, 0.047745555100466235, -0.0015886005533402108, -0.009665488156381324, -0.027662763059893906, 0.00663762113039563, 0.02484087245445992, 0.021627625206427713, 0.044491115455423634, 0.02683885365239681, 0.03544870724013822, -0.011781906576118096, -0.031287964080352094, -0.013707795025690132, 0.004601019848370406, -0.014037358416159945, -0.009310177422304248, 0.023502019900107782, -0.01162742344579707, -0.025458804975744022, -0.06583037153103705, 0.020824312928758377, -0.031102584323966866, 0.06047495758833824, 0.024243537063003577, 0.03676696080201747, 0.009444062491474949, 0.03373909331037049, -0.00155384184901798, -0.04195759398080394, 0.023275444021421902, -0.0418134066214291, -0.027436187181208025, -0.012049676714459499, 0.029763731769614728, -0.019794426635048292, -0.009433763926561069, 0.041710420972290295, -0.0603925690690272, -0.04395557145345057, 0.014881865884807364, 0.003743638940749995, 0.014686187563508252, -0.06821970564628191, 0.007152564742911955, 0.058291598496661254, 0.0038131563493944563, -0.06331744718624512, -0.01139054900219731, -0.033100563659258626, 0.005715872096587697, 0.007013529925623032, 0.02486146958428768, -0.017312397984998, 0.01942366712227783, 0.004837893826308884, 0.01333703551291967, -0.02469668882037534, -0.017096122533871126, 0.037384893323301575, -0.010175282952101992, -0.046468495798242505, -0.004765801543605312, -0.03581946675290868, 0.04976413342823088, 0.011215468742048523, -0.05071163120262993, 0.005406906301606928, 0.02430533031513199, -0.008748888870691614, 0.06570678130148998, 0.04039216368512079, -0.04150444222343218, 0.02127746282348501, -0.00974787946966006, -0.03952705815532304, -0.05380129008376019, -0.04350242342136906, -0.018259893896751915, 0.033059369399603106, -0.03925928801698164, -0.01813630925514022, -0.022369144231968636, -0.006230815709104023, 0.009531603087210624, 0.00572617112716286, 0.021833602092640705, -0.029516558761101087, 0.036107834021077846, 0.05454280910930111, 0.013543012399132663, 0.07093860873993196, -0.01432572661565167, 0.03400686717400215, -0.016488488577500904, 0.010762317915999325, -0.0003588512150121852, 0.0006771506665227613, 0.024161146681047407, 0.012636712609679397, 0.011050686115491053, -0.011740710453817447, -0.00786833549352305, 0.020123990025518103, 0.05252423078153646, 0.025355815601314963, -0.02842487921526259, -0.008681946336106264, -0.0018975665811516215, 0.011956986836266883, -0.0006575184450790743, 0.041978191110631696, 0.06500646398618509, -0.01740508879451318, -0.008362681510550333, -0.00786833549352305, 0.005509894744713424, -0.0014418416959505569, -0.0048250201545052525, 0.04885783363877762, 0.0029815225525506696, 0.040907106831975834, 0.014933360572021895, -0.0171785129158273, 0.01570577529230446, -0.016622375509316733, 0.0036355007495252768, 0.042802098655483664, 0.06789014411845723, 0.021607028076599952, -0.04123667208509077, 0.05252423078153646, 0.0018370607660527667, -0.02617972500881206, 0.0056746769056096125, 0.02854846571951941, -0.029578352013229496, 0.025520598227872435, -0.016025040117860392, -0.03991841479792127, -0.002724050746292507, -0.008470820167436333, -0.008398727419071477, 0.020546244225503097, 0.0007286450044913297, 0.05050565245377181, -0.035613488004050564, -0.0052369748582538, 0.034995555482766456, 0.0038595012884907643, 0.037735055706244275, -0.03903271213829576, -0.039444669636012, 0.03188529947180844, 0.058291598496661254, 0.04284329664042944, 0.034954361223110936, 0.032091274495376305, -0.00037590870791591165, -0.011761308514967771, 0.05132956372391403, -0.014294829989587466, 0.01040700718192225, 0.010803514038299976, 0.0069208400474304165, -0.05524313387518651, 0.04030977516580975, 0.018424676523309383, -0.015613085414111844, 0.0017160490194397366, -0.008594406671693153, -0.06035137108408142, -0.0319882888462375, -0.011163974054833993, 0.032750405001606184, 0.007234955590529409, 0.01767285893285458, 0.03213247248032208, 0.0008689670841868278, 0.016385501065716974, 0.0454798074894782, 0.003393477256299217, 0.007662358607310058, -0.009783925378181206, -0.010216478143080078, -0.028898626239816982, 0.009418316079190248, -0.008383279571700658, -0.01243073479214384, 0.010782915977149652, 0.01788913624662658, -0.0430492716639973, 0.03507794772736776, 0.01419184154648097, -0.04444991747047785, -0.02514983871510197, 0.0051236873845721415, -0.0027626715288727633, -0.014531704433187227, -0.01152443407136801, -0.03824999885309932, -0.011287560559090814, -0.02286348838635079, 0.03546930436996598, 0.032894588635690766, -0.010134086829801343, 0.005144284980061184, 0.039238690887153885, 0.006462540404585561, -0.002063635946246724, -0.02150403870217089, 0.036149032006023624, -0.014552301563014987, -0.0159529483008181, 0.03373909331037049, -0.05450161484964559, -0.008846728962663735, 0.03709652605513241, -0.03007269803025678, -0.0017057502216952152, -0.0012628987754671423, -0.010752019351085445, 0.028939822362117635, 0.013182552382598644, -0.004575272504763141, -0.03124676795805145, 0.0804547658424169, -0.0568085604455794, 0.011792205141031976, 0.02776575057167784, -0.050258479445258165, -0.022121971223454995, 0.04168982011717228, 0.020144587155345863, -0.005458400523160176, 0.039444669636012, 0.0028476372505493275, -0.02842487921526259, 0.01623101700407338, -0.009835420065395735, -0.021648222336255473, 0.025417608853443373, 0.05639660667315342, 0.0022039580841498826, 0.03754967781250417, 0.01297657456506309, 0.028733845475904643, -4.582192144102956e-05, -0.006441942809096519, -0.0014160944687586123, 0.016467891447673143, -0.009073303910027052, -0.07192730077398653, 0.027992326450363716, -0.039465266765839765, -0.0013375655829838645, 0.0024743033293810365, -0.02622092113111271, 0.011205169245812078, 0.013851978659774713, 0.01574697141460511, -0.05235945001762412, -0.009320476918540693, 0.008491417297264093, 0.045109047976707735, 0.03516033997196906, -0.03487196897850964, -0.1863683292099973, 0.015674879597562818, -0.027168417042866624, 0.04807512035358117, -0.006313206556721476, 0.014418416493844287, -0.029434168379144917, 0.03744668843807511, 0.07266881979952745, -0.061257674598824946, 0.024387722559733288, 0.029578352013229496, 0.01598384399555974, 0.0032467185153248835, 0.026880047912052334, 0.032750405001606184, 0.036416802144365025, 0.015046647580042271, 0.0025875908030626948, -0.02469668882037534, -0.010092891638823258, 0.017281502290256358, -0.02271930475226621, 0.007234955590529409, -0.0603925690690272, 0.016776857708315194, 0.01492306107578545, -0.02617972500881206, -0.04057754530415115, 0.03880613998490014, 0.02807471683231989, -0.029557754883401736, 0.0210817845021859, -0.016509087569973793, -0.043378836917112244, -0.01571607385721834, 0.045315023000275595, 0.01401676035500962, -0.025129239722629083, 0.018991114357378956, 0.004407916168299765, -0.05244184226222542, -0.016972536029614307, 0.014428715990080731, -0.00888792415364182, -0.029454765508972677, -0.032626818497349365, 0.00578281509683433, 0.021668821328728362, -0.0045443758786989355, 0.023934570802361527, -0.002324969714347592, -0.008470820167436333, -0.047663166581155186, -0.10043457037120529, 0.04168982011717228, 0.05062923895802863, -0.0192382873658926, 0.006009390044197646, 0.0021820729352159634, 0.025582391480000844, 0.02290468450865144, -0.02492326283641609, -0.046015347766161, 0.015623383979025724, 0.057467690951809286, 0.04926979113649386, 0.03448061233591142, 0.003478442977975781, 0.0347071882145973, 0.0035531099019078236, 0.003316235923969345, 0.032091274495376305, 0.02306946713520891, 0.01922798880097872, -0.0493521796558049, 0.0021563255916086984, -0.05062923895802863, 0.014088853103374474, 0.004621617443859449, -0.003295638095649661, -0.0016787156738890358, 0.023172454646992843, -0.03215306961014984, 0.08296769018720883, -0.07855977029361881, 0.008403876701528418, 0.008233945723836572, -0.045315023000275595, 0.00225287766447466, -0.06171082263090645, 0.05289499029430692, 0.025417608853443373, -0.021998384719198173, -0.016158925187031093, 0.02482027532463216, 0.009001211161662196, 0.07126817026775664, 0.008100060654665871, 0.0243671235672604, 0.013759288781582097, -0.03145274484426444, 0.006488287282531545, -0.0017456583248897067, 0.05499596086667287, -0.028836832987688573, -0.05116478296000169, -0.010000201760630642, -0.027703957319549426, 0.00395991509036879, 0.026056138504555237, -0.016951938899786547, -0.0024253837490562586, -0.056932146949836226, -0.03184410148686266, 0.021401049327741832, -0.010381259838314984, -0.028836832987688573, -0.011936388775116559, -0.008022818623844076, -0.02083461149367226, -0.02986672114404379, -0.007626312698788913, 0.015283522023642032, -0.04412035594265317, 0.02863085610147558, -0.05985702506705414, -0.008254543784986896, -0.012090871905437584, -0.044573503974734675, 0.008285440411051101, 0.021813004962812944, -0.009057855131333666, -0.029413569386672028, -0.022121971223454995, 0.0017932905846002496, -0.03215306961014984, -0.04782794734506753, -0.007147414994793733, 0.0037024435169412686, -0.0008013807728790392, 0.013234047069813175, -0.03722011255938923, 0.04208118048506076, -0.008486268014807154, 0.005064468773672201, 0.011328755750068899, 0.05919789828611451, 0.03149394282921022, 0.016694467326359024, -0.004418214733213645, 0.001179864151127251, 0.023852180420405357, -0.01296627600014921, 0.01933097631276265, 0.01522172877151362, 0.0031874999044249432, -0.043255250412855425, -0.0024717284553219254, -0.007662358607310058, 0.005079917086704304, -0.015489498909855022, -0.003341983034745969, 0.0493521796558049, 0.0025863034824484595, 0.029825525021743137, -0.05709693143903882, -0.033018175139947585, 0.01951635606914788, -0.020659532164846037, -0.007631461981245853, -0.03345072604220133, 0.005834309318387578, -0.029084005996202214, -0.06220516864793373, 0.0032080977327446267, 0.012863287557042713, 0.01431542805073779, 0.05417204959653065, -2.570694203407875e-05, 0.010386409120771925, 0.029413569386672028, 0.01944426425210559, 0.020793417234016738, -0.009191740200504367, 0.027724556312022315, 0.0627407126499068, -0.0164369957529315, -0.026076735634382998, 0.016292810256201794, 0.0005303917509254471, -0.020000403521261284, -0.015386510466748528, -0.018434975088223265, -0.009444062491474949, -0.025788368366213836, 0.011287560559090814, 0.016354603508330203, -0.029495961631273326, -0.02617972500881206, 0.030855411315453225, -0.0016349454924365187, -0.07798303575728048, -0.013367932138983876, -0.0075645194466605024, -0.017940629071195983, -0.09722132126052796, -0.038352988227528376, -0.06620112731851725, 0.011225767306962403, 0.05932148479037134, 0.018476171210523914, 0.05112358497505591, 0.003370304786751063, 0.021998384719198173, 0.014521404936950782, 0.009438913209018008, 0.02337843339585096, 0.013851978659774713, 0.03511914198702328, 0.0466332802874451, 0.01596324686573198, -0.017034329281742717, -0.008089762089751991, 0.031040791071838457, -0.025417608853443373, 0.027559773685464847, 0.02486146958428768, 0.011555330697432215, -0.02337843339585096, 0.005700423783555595, -0.02097879699040197, -0.033141761644204404, 0.014964256266763535, -0.008058865463687784, 0.0344394180762559, -0.013594507086347192, -0.04096890194674937, 0.055284328134842034, 0.0388267371147279, -0.025829564488514485, -0.005005250162772261, -0.04428513670656551, 0.04926979113649386, 0.011318457185155019, 0.009268982231326162, 0.002948051285257994, 0.053842488068705965, -0.009917810447351906, -0.015273222527405587, -0.0014057956710140911, -0.01782734299449817, -0.011936388775116559, -0.014933360572021895, -0.034130453678258975, -0.03001090477812837, 0.01802302131579728, -0.003478442977975781, -0.029495961631273326, -0.026365104765197288, -0.02331664014372255, -0.01315165575653444, 0.0034372475541670543, 0.07509935562500834, 0.02315185751716508, 0.041010096206404896, 0.030793618063324816, 0.02679765753009616, -0.003846627616687132, 0.00980452343933153, -0.025046849340672913, 0.04012439354677939, 0.02486146958428768, 0.04428513670656551, 0.032750405001606184, -0.03326534814846123, 0.001071082416010736, 0.0010247374769144283, 0.0005693343636592623, -0.03983602627861022, 0.009778776095724265, -0.030299272046297534, 0.00024491999371191903, 0.03666397515287867, -0.032832793520917225, 0.017477180611555468, -0.013841680094860833, -0.08478028976611536, 0.009480109331318659, 0.01234834441018767, -0.02052564523303021, -0.010370961273401104, -0.014830371197592835, -0.02294588063095209, 0.010329766082423019, -0.00790438233336676, -0.004461985031081483, -0.018373181836094855, 0.0028424879680923874, 0.027786349564150728, 0.015262923962491706, -0.04618012853007334, 0.04926979113649386, -0.033368337522890285, -0.010144386326037787, -0.008187601250401546, -0.011709813827753242, 0.04201938537028722, -0.013316437451769346, -0.009660338873924385, -0.0012081860195476656, -0.01804361844562504, 0.0011013352653525032, -0.06414135473109708, -0.03332713953794451, 0.014562601059251432, -0.03771445857641651, -0.0627407126499068, 0.01621041987424562, 0.02490266570658833, -0.027971727457890828, 0.07802423001693601, -0.01572637242213222, -0.05417204959653065, 0.0494345719004062, -0.030381664290898832, 0.018640953837081385, -0.05165912897702897, 0.01893961967016443, -0.03229725324423442, 0.018228998202010273, -0.015252625397577825, 0.01777584830728364, 0.01168921669792548, -0.006601575221874485, 0.05536672037944333, 0.0009944845111573408, -0.01296627600014921, 0.00029078212937022835, 0.03798222871475791, 0.034563004580512716, -0.005875504975026946, 0.005504745462256484, -2.2810385159548898e-05, -0.0179303305062821, 0.024222939933175817, 0.012986874061299534, 0.011555330697432215, 0.04358481194068011, 0.008630452580214299, 0.00797132486795211, 0.012317447784123465, 0.045109047976707735, -0.041133682710661715, -0.012235056470844729, 0.018074516003011812, 0.05652019317741024, 0.03188529947180844, 0.03794103445510239, -0.008244244288750452, -0.024490710071517218, 0.009959006569652555, -0.03724070968921699, -0.06912600916102543, -0.024799676332159272, 0.03186470234198068, 0.009253533452632778, 0.04885783363877762, -0.02681825465992392, 0.014881865884807364, 0.05845637926057359, -0.028939822362117635, 0.023934570802361527, 0.01767285893285458, -0.012863287557042713, -0.01938247099997718, -0.01907350473933513, -0.046592082302499324, 0.030896607437753874, 0.021607028076599952, 0.00963459153031712, 0.0650476582458406, -0.03005209903778389, 0.005136561056375774, 0.00798162343286599, -0.007729301141895409, 0.027745153441850075, 0.001095542206173125, -0.034254040182515794, 0.02809531396214765, -0.04473828846393727, 0.025602988609828604, -0.047704360840810714, 0.012265953096908934, 0.0005564607500632901, -0.01592205074343133, 0.004675686772302449, 0.034686591084769534, 0.0008400014972516354, -0.010324615868643514, 0.005932148479037134, -0.014562601059251432, 0.03229725324423442, 0.011442043689411839, -0.017034329281742717, -0.01760076711581229, -0.02834248697066129, 0.036849353046618766, 0.07563489590169115, -0.023419627655506484, 0.049970112177089, -0.012276251661822815, 0.03167932072295032, -0.03215306961014984, -0.0021318658014463096, 0.026076735634382998, 0.02337843339585096, 0.01152443407136801, 0.033986266318884135, 0.04679806105135745, 0.055160741630585215, -0.03705533179547689, -0.027086024798265326, 0.008470820167436333, 0.03810581521901474, 0.00969638478244553, 0.02335783440337807, -0.011287560559090814, 0.08478028976611536, -0.030731824811196403, 0.03027867491646977, -0.02805411970249213, -0.005103089789083099, 0.013038367817191499, -0.04535622098522137, 0.003846627616687132, -0.036684572282706426, -0.04992891791743348, 0.011472940315476046, 0.024511309063990107, 0.0033059368933941826, 0.001643956969566805, -0.026694668155667102, -0.015530694100833109, 0.052235863513367294, -0.07921890079984868, -0.01776554974236976, -0.005110813712768509, 0.018115710262667332, 0.05371890156444915, -0.019948908834046753, -0.014717084189572458, 0.0017855664280841982, -0.04111308558083395, 0.01077261741223577, 0.008805532840363084, 0.02247213174375257, 0.059486269279573935, -0.003903271353527961, 0.030381664290898832, 0.03794103445510239, 0.02966074239518567, -0.008156704624337341, -0.01601474155294651, -0.03419224506774225, -0.03763206633181521, 0.03604604263159456, 0.022080775101154346, -0.03913570151272482, 0.023872777550233117, -0.005309067140957372, -0.005015549193347423, -0.017744950749896873, 0.07637641492723207, -0.020803715798930617, -0.04926979113649386, -0.020082793903217454, -0.008264842349900776, 0.00480184791778774, 0.02411995055874676, 0.029186995370631276, 0.0603101768244259, -0.049970112177089, -0.007353392346668007, -0.057467690951809286, -0.014027059851246065, 0.00396248973159726, -0.018661550966909145, 0.006246264022136125, -0.015551292161983433, -0.04605654202581652, 0.0662423290287533, 0.0356752831188241, 0.015530694100833109, 0.057014539194437525, 0.018218699637096394, -0.014480209745972698, -0.006663368474002895, -0.01693133990731366, 0.009907511882438026, 0.010515144907485684, 0.01162742344579707, -0.020010702086175162, 0.03728190767416277, 0.015324717214620117, 0.01241013766231608, -0.012945677938998883, -0.0008657486662359196, -0.029269385752587446, 0.001461152087240685, -0.039939015653039284, -0.020958197997929078, -0.02063893317237315, -0.04309046964894308, -0.014768577945464424, -0.006508885343681869, 0.020021000651089044, 0.0035891558104289693, -0.06088691508605448, -0.041319064329692075, 0.01947516180949236, 0.07967205255722044, -0.0016079109446303392, -0.004755502978691432, 0.07069143573141833, 0.011050686115491053, -0.02278109800439462, -0.03326534814846123, 0.043337642657456724, 0.00395991509036879, -0.0071783116208579386, 0.007399737285764314, -0.018290791454138682, 0.0387443448701266, -0.00584460834896274, 0.028795638728033052, -0.010309168021272692, -0.0073224957206038015, 0.008022818623844076, -0.023934570802361527, -0.01744628491681383, 0.07542891715283302, 0.04482067698324831, 0.006050585700837014, -0.0025077745966737117, 0.03483077471885412, -0.0038852483992673882, 0.03724070968921699, -0.02138045219791407, -0.023563813152236192, -0.00658097716072416, 0.03530452360605364, 0.016900444212572016, 0.023172454646992843, 0.003339408393517499, -0.0069723342689836645, 0.012049676714459499, 0.005030997506379526, -0.018682148096736906, -0.06657189055657797, 0.019722334818006, -0.03378029129531627, 0.039197496627498364, -0.01230714828788702, -0.01912499942654966, -0.03427463731234355, -0.0027781198419048656, -0.0412778663447463, -0.005607734371024261, 0.028218900466404472, -0.0026622577269947373, 0.02490266570658833, -0.01925888449572036, 0.023646203534192365, 0.02282229412669527, 0.005442952210128074, 0.00043255250296440103, 0.012152665157565995, -0.01742568592434094, 0.02117447531170108, -0.0026120505932250835, 0.02461429657577404, -0.0023687397793847884, -0.05742649296686351, -0.01918679267867807, -0.028466073474918113, -0.0036097536387486528, -0.1046365115159372, 0.010793214542063532, -0.048363487621750335, -0.015149636023148767, 0.021998384719198173, 0.002146026793864177, 0.04395557145345057, -0.017085823968957248, 0.0028785338766135326, -0.03516033997196906, -0.01819810250726863, -0.04049515305954985, 0.008532613419564744, 0.010443053090443395, 0.00311025833926443, 0.009073303910027052, -0.040556944449033135, -0.023934570802361527, -0.01771405505515523, 0.01077261741223577, -0.052112277009110475, 0.016694467326359024, -0.007821991020088024, -0.00821849787646575, 0.0494345719004062, -0.05668497394132258, 0.0809903061190997, -0.03631381276993596, -0.031287964080352094, 0.02652988739175476, 0.008053715249908281, 0.03501615633788448, 0.01621041987424562, -0.025232229097058145, 0.01333703551291967, -0.008213347662686247, -0.04313166390859861, -0.01138025043728343, 0.020566841355330857, -0.05219466925371177, -0.015046647580042271, 0.029825525021743137, -0.010139236112258284, 0.0192382873658926, 0.04733360132804025, 0.014593497685315638, -0.12366881827032654, -0.008960015970684111, -0.021792405970340056, 0.04968174490891984, 0.01808481456792569, 0.01582936179656128, 0.00888792415364182, -0.0019091528159256984, 0.0006346678056844792, 0.03213247248032208, 0.03952705815532304, -0.0018023020617305358, 0.027456784311035785, 0.0002059773809781038, -0.002565705654128776, -0.02146284257987024, 0.09046526896192911, -0.03229725324423442, -0.025005653218372264, -0.01071082416010736, 0.018970517227551196, 0.014603796250229518, 0.021915992474596874, -0.007415185598796417, -0.035881258142391965, 0.005376009675542723, 0.027724556312022315, -0.006380149556968109, 0.022678110492610686, -0.005448101492585014, -0.023213650769293492, 0.05755007947112033, -0.004933158345729971, -0.032873991505863, 0.005334814018903356, -0.04799272810897987, -0.009155694291983221, 0.0212980618159579, -0.02671526714813999, -0.0592390962710603, 0.015499797474768904, 0.016251615996546273, 0.04980533141317666, -0.048363487621750335, -0.014644991441207603, 0.04745718783229707, 0.011297859124004694, 0.027436187181208025, -0.040247980051036206, -0.04786914160472305, -0.003751363097266046, -0.1253166333600305, 0.05664377968166706, -0.03176171296755162, 0.027250807424822793, 0.0010183006410126121, 0.007039276803569015, -0.03783804508067334, -0.012688206365571362, 0.033244751018633466, -0.007579967759692606, 0.0038723747274637555, 0.027147818050393735, -0.04346122916171354, -0.03528392647622588, -0.007806542707055922, -0.02104059024253038, -0.010355512494707718, -0.01802302131579728, -0.052071082749454954, -0.024222939933175817, 0.018991114357378956, -0.00024781652330160814, 0.011009490924512968, -0.017157915785999536, 0.005535642088320689, -0.010479098998964539, 0.053966074572962784, -0.015386510466748528, -0.020371163034031744, 0.04107189132117843, 0.024099353428918998, -0.002319820199060011, -0.01905290760950737, 0.02521163196723038, -0.005345113049478518, -0.03530452360605364, -0.027250807424822793, -0.04313166390859861, -0.02088610618088679, 0.052112277009110475, -0.023399030525678724, -0.017312397984998, 0.005074767804247364, 0.024470112941689458, 0.058291598496661254, -0.00334713255003355, -0.027580370815292608]\n"
          ]
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "print(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['example-index']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import and initialize Pinecone client\n",
        "\n",
        "import os\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),\n",
        "    environment=os.getenv('PINECONE_ENV')\n",
        ")\n",
        "pinecone.list_indexes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [],
      "source": [
        "# Upload vectors to Pinecone\n",
        "\n",
        "index_name = \"example-index\"\n",
        "#pinecone.create_index(\"example-index\", dimension=1024)\n",
        "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='To do this, an autoencoder uses something called an artificial neural network. This is a type of', metadata={}), Document(page_content='An autoencoder is a type of machine learning, which is a way for computers to learn by themselves.', metadata={}), Document(page_content='is important and what is not.', metadata={}), Document(page_content='The autoencoder then takes the hidden representation and turns it back into the original input', metadata={})]\n"
          ]
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "\n",
        "query = \"What is magical about an autoencoder?\"\n",
        "result = search.similarity_search(query)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4Ogz8luZNRnJ"
      },
      "outputs": [],
      "source": [
        "# Import Python REPL tool and instantiate Python agent\n",
        "\n",
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.llms.openai import OpenAI\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "BVHMDj0sNi09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to solve the equation 3 * x**2 + 2*x -1\n",
            "Action: Python REPL\n",
            "Action Input: import numpy as np\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can use the numpy function to solve the equation\n",
            "Action: Python REPL\n",
            "Action Input: np.roots([3,2,-1])\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The output of the function is the roots of the equation\n",
            "Final Answer: The roots of the equation 3 * x**2 + 2*x -1 are -1 and 0.33333\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The roots of the equation 3 * x**2 + 2*x -1 are -1 and 0.33333'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Execute the Python agent\n",
        "\n",
        "agent_executor.run(\"Find the roots(zeros) of the quadratic function 3 * x**2 + 2*x -1\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
